{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOzO5A/UAkeWAwVp0kgxOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/CV-2025/blob/main/Week_01/Lab_1_Feature_Extraction_and_ML_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab. \\#1. Feature Extraction and Machine Learning\n",
        "By *First name* *Second name*.\n",
        "\n",
        "*Month, Day, 2025.*"
      ],
      "metadata": {
        "id": "dviRg5xn5mza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "fS8QkXU47uNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lab compares two approaches to machine learning (ML) and computer vision (CV). The *first approach* involves using an ML model for both automatic feature extraction and subsequent classification. The *second approach* processes hand-designed features, such as geometric features of objects in images, with an ML classification model. Historically, the second approach preceded the first. However, in modern coding, the first approach is easier to implement. Thus, this work is organized in order of increasing model complexity.\n",
        "\n",
        "The **main problem** addressed in this work is determining the better approach. The choice may not be straightforward, as many modern competitions related to CV problems, such as those submitted on [Kaggle](https://www.kaggle.com/competitions), often use a hybrid trick: instead of solving a CV problem directly with an image-processing model (e.g., a convolutional neural network or a visual transformer), the best solutions are often based on preliminary feature extraction followed by the analysis of tabular data using models like gradient boosting.\n",
        "\n",
        "The **dataset** used in this work is the MNIST database, consisting of $28\\times28$ pixel images of handwritten digits, with a training subset of 60,000 examples and a test subset of 10,000 examples.\n",
        "\n",
        "The *first approach* can be implemented with a simple multi-layer perceptron (MLP) model to solve a multi-class classification problem by minimizing the cross-entropy (CE) loss, as described in [Prince, 2024](https://udlbook.github.io/udlbook/).\n",
        "\n",
        "The *second approach* can also be implemented using the same network architecture and loss function but with a modified dataset. In this case, the image dataset is replaced with a tabular dataset of hand-designed features. These features can be extracted using standard tools in [Scikit-learn](https://scikit-learn.org/1.5/modules/feature_extraction.html) or [OpenCV](https://docs.opencv.org/3.4/d0/d49/tutorial_moments.html)."
      ],
      "metadata": {
        "id": "EvP6IWSB5s_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks and Requirements  \n",
        "\n",
        "- Fill in your name and date information above.  \n",
        "- Review the [Lightning framework](https://lightning.ai/docs/pytorch/stable/) (Level Up, Core API, Optional API sections of the manual).  \n",
        "- Briefly review the [ClearML](https://clear.ml/docs/latest/docs/integrations/pytorch_lightning/) documentation.  \n",
        "- Run the code below cell by cell and replace the placeholder text \"Enter your code here\" with your implementation in the missing code fragments.  \n",
        "- If the code works properly, implement five parallel tests. Otherwise, fix the code before proceeding.  \n",
        "- Fill in the table, add figures in the Results section, and complete the Conclusion section of the lab.  \n",
        "- Address the Questions section and prepare to defend the lab.  \n",
        "\n",
        "### Bonus (complete one of the following as a bonus task):  \n",
        "- Apply a t-SNE model to visualize both the original image dataset and the table dataset with hand-extracted features.  \n",
        "- Add one or more features in the `TabularDataModule` to enhance the tabular model's capability.  \n",
        "- Visualize the feature extraction process implemented in the `extract_features` function using one or more samples.  \n",
        "- Apply a gradient boosting model to solve the table data classification problem in the second approach. Fine-tune both models to improve accuracy.  \n",
        "\n",
        "### A List of Blocks with Missing Code  \n",
        "- Preparation of simulation models/Set the model/Logging\n",
        "- Approach #2: Hand-designed feature extraction followed by tabular data classification using the ANN.  \n",
        "- Results and Discussion.  \n",
        "- Conclusion."
      ],
      "metadata": {
        "id": "fZWswAni70vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation of simulation models"
      ],
      "metadata": {
        "id": "kN9yU_U6766c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and Install Libraries"
      ],
      "metadata": {
        "id": "9mpwlpoX5TI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMPnV0nV4_-I",
        "outputId": "f9721f78-389b-4f85-a471-fd5e3ccf6f68",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting clearml\n",
            "  Downloading clearml-1.17.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.10/dist-packages (from clearml) (24.3.0)\n",
            "Collecting furl>=2.0.0 (from clearml)\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from clearml) (4.23.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from clearml) (1.26.4)\n",
            "Collecting pathlib2>=2.3.0 (from clearml)\n",
            "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from clearml) (11.1.0)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from clearml) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from clearml) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from clearml) (2.32.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from clearml) (2.3.0)\n",
            "Collecting pyjwt<2.10.0,>=2.4.0 (from clearml)\n",
            "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.10/dist-packages (from clearml) (0.35.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.11)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->clearml) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6.0->clearml) (0.22.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->clearml) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->clearml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->clearml) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clearml-1.17.0-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pyjwt, pathlib2, orderedmultidict, lightning-utilities, furl, torchmetrics, clearml, pytorch-lightning\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "Successfully installed clearml-1.17.0 furl-2.1.3 lightning-utilities-0.11.9 orderedmultidict-1.0.1 pathlib2-2.3.7.post1 pyjwt-2.9.0 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning clearml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch modules\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import datasets, transforms\n",
        "#sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Numpy\n",
        "import numpy as np\n",
        "#Pandas\n",
        "import pandas as pd\n",
        "#Lightning & logging\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "#Image processing (OpenCV)\n",
        "import cv2\n",
        "#Data observation\n",
        "import os\n",
        "from pathlib import Path\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#Logging\n",
        "from clearml import Task"
      ],
      "metadata": {
        "id": "fDHrafErmo43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Models"
      ],
      "metadata": {
        "id": "ealb85K93wDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulation Settings"
      ],
      "metadata": {
        "id": "GHIKBWI93-zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the current directory"
      ],
      "metadata": {
        "id": "kiYPAzh54gjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd() #returns the current working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "phE7U1vu31BR",
        "outputId": "243193f7-d72b-4c0f-e6d4-51da046450bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
        "print(f'CHECKPOINT_PATH: {CHECKPOINT_PATH}')\n",
        "\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EVwTLDiNYyc",
        "outputId": "273eea86-1c4d-4884-a66a-bf98ba3f0e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECKPOINT_PATH: saved_models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the reproducibility options"
      ],
      "metadata": {
        "id": "3WK77wcO6sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for setting the seed to implement parallel tests\n",
        "SEED = 42 # random seeds are 42, 0, 17, 9, 3\n",
        "pl.seed_everything(SEED)\n",
        "\n",
        "# # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "# torch.backends.cudnn.deterministic = True\n",
        "# torch.backends.cudnn.benchmark = False\n",
        "# torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# torch.manual_seed(SEED)\n",
        "# np.random.seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YX7JeP93-TZ",
        "outputId": "8a691858-0d64-4e05-9284-f551dd2fa11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logging"
      ],
      "metadata": {
        "id": "_7ULmzow4jSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To configure ClearML in your Colab environment, follow these steps:\n",
        "\n",
        "---\n",
        "\n",
        "*Step 1: Create a ClearML Account*\n",
        "1. Go to the [ClearML website](https://clear.ml/).\n",
        "2. Sign up for a free account if you don’t already have one.\n",
        "3. Once registered, log in to your ClearML account.\n",
        "\n",
        "---\n",
        "\n",
        "*Step 2: Get Your ClearML Credentials*\n",
        "1. After logging in, navigate to the **Settings** page (click on your profile icon in the top-right corner and select **Settings**).\n",
        "2. Under the **Workspace** section, find your **+ Create new credentials**.\n",
        "3. Copy these credentials for a Jupiter notebook into the code cell below.\n",
        "\n",
        "---\n",
        "\n",
        "*Step 3: Accessing the ClearML Dashboard*\n",
        "1. Go to your ClearML dashboard (https://app.clear.ml).\n",
        "2. Navigate to the **Projects** section to see your experiments.\n",
        "3. Click on the experiment (e.g., `Lab_1`) to view detailed metrics, logs, and artifacts.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "C97DLT0gK37A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWNNZT7EWA5ZTV\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH41"
      ],
      "metadata": {
        "id": "lTXMGNya32_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task.init(project_name=\"CV-2025\", task_name=f'Lab_1_seed={SEED}_img')\n",
        "print(\"ClearML is configured correctly!\") #just to make you feel better"
      ],
      "metadata": {
        "id": "KrrbCx71RUDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "BujHK4sw7cA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "Wb0uJtxz-E--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'MNIST'\n",
        "NS = {\n",
        "    'train': 55000,\n",
        "    'val': 5000,\n",
        "    'test': 10000\n",
        "} # for MNIST\n",
        "\n",
        "SIZE = 28 #image size\n",
        "NUM_CLASSES = 10\n",
        "CLASS_NAMES = ['zero' ,'one', 'two', 'three', 'four',\n",
        "               'five', 'six', 'seven', 'eight', 'nine']"
      ],
      "metadata": {
        "id": "hWRDBJbO7k_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization parameters"
      ],
      "metadata": {
        "id": "qP6TSQ-Z-Hxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For the MNIST dataset\n",
        "MEAN = np.array([0.1307])\n",
        "STD  = np.array([0.3081])"
      ],
      "metadata": {
        "id": "Oh-UxEQ3-Le3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms"
      ],
      "metadata": {
        "id": "StCJNi9PDVZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collect parameters"
      ],
      "metadata": {
        "id": "GwaBDKEvD5ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model parameters\n",
        "LOSS_FUN = 'CE' # 'CE', etc.\n",
        "ARCHITECTURE = 'MLP' # 'MLP', etc.\n",
        "\n",
        "#Collect the parameters (hyperparams and others)\n",
        "hparams = {\n",
        "    \"seed\": SEED,\n",
        "    \"lr\": 0.0001,\n",
        "    'weight_decay': 0.0,\n",
        "    \"dropout\": 0.0,\n",
        "    \"bs\": 64,\n",
        "    \"num_workers\": 2,\n",
        "    \"num_epochs\": 5,\n",
        "    \"criterion\": LOSS_FUN,\n",
        "    \"num_samples\": NS,\n",
        "    \"im_size\": SIZE,\n",
        "    \"mean\": MEAN,\n",
        "    \"std\": STD,\n",
        "    \"n_classes\": 10,\n",
        "}\n",
        "#Visualization\n",
        "vis_params = {\n",
        "    'fig_size': 5,\n",
        "    'num_samples': 5,\n",
        "    'num_bins': 50,\n",
        "}"
      ],
      "metadata": {
        "id": "NSyUzYCSD0v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "OQsu5FcbFfwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lightning"
      ],
      "metadata": {
        "id": "ZAOMnXlqFofC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data module"
      ],
      "metadata": {
        "id": "2N2vslXcUvGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Approach #1: dataset of images\n",
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.seed = params['seed']\n",
        "        self.batch_size = params['bs']\n",
        "        self.num_workers = params['num_workers']\n",
        "        self.mean = params['mean']\n",
        "        self.std =  params['std']\n",
        "        self.ns = params['num_samples']\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Download MNIST dataset\n",
        "        datasets.MNIST(root='./data', train=True, download=True)\n",
        "        datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Split dataset into train and validation sets\n",
        "        mnist_full = datasets.MNIST(root='./data', train=True,\n",
        "                                    transform=self.transform)\n",
        "        pl.seed_everything(self.seed)\n",
        "        self.mnist_train, self.mnist_val = random_split(mnist_full,\n",
        "                                                        [self.ns['train'],\n",
        "                                                         self.ns['val']])\n",
        "        self.mnist_test = datasets.MNIST(root='./data', train=False,\n",
        "                                         transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers, shuffle=True)\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers,)\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.mnist_test, batch_size=self.batch_size,\n",
        "                          shuffle=False)\n",
        "\n",
        "# Approach #2: tabular dataset of extracted features\n",
        "class TabularDataModule(MNISTDataModule):\n",
        "    def __init__(self, params):\n",
        "        super().__init__(params)\n",
        "        self.feature_names = [\n",
        "            'mean_intensity', 'std_intensity', 'num_edges',\n",
        "            'aspect_ratio', 'cx', 'cy', 'num_contours', 'area',\n",
        "            'perimeter', 'inertia', 'compactness', 'eccentricity'\n",
        "        ]\n",
        "        self.scaler = StandardScaler()  # Initialize the StandardScaler\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Call the parent class's setup method to load and split the MNIST dataset\n",
        "        super().setup(stage)\n",
        "\n",
        "        # Extract features from the MNIST datasets\n",
        "        self.train_features, self.train_labels = self._extract_features(self.mnist_train)\n",
        "        self.val_features, self.val_labels = self._extract_features(self.mnist_val)\n",
        "        self.test_features, self.test_labels = self._extract_features(self.mnist_test)\n",
        "\n",
        "        # Normalize the features using StandardScaler\n",
        "        self.scaler.fit(self.train_features)  # Fit the scaler on the training data\n",
        "        self.train_features = self.scaler.transform(self.train_features)\n",
        "        self.val_features = self.scaler.transform(self.val_features)\n",
        "        self.test_features = self.scaler.transform(self.test_features)\n",
        "\n",
        "    def _extract_features(self, dataset):\n",
        "        \"\"\"\n",
        "        Extract features from a dataset of MNIST images.\n",
        "        :param dataset: A PyTorch dataset of MNIST images.\n",
        "        :return: A tuple (features, labels) where features is a NumPy array and labels is a NumPy array.\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        labels = []\n",
        "        for image, label in dataset:\n",
        "            # Convert image to numpy array\n",
        "            image_np = image.squeeze().numpy()\n",
        "\n",
        "            # Extract features\n",
        "            feature_vector = extract_features(image_np)\n",
        "            features.append(feature_vector)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(features), np.array(labels)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Create a TensorDataset from features and labels\n",
        "        train_dataset = TensorDataset(\n",
        "            torch.tensor(self.train_features, dtype=torch.float32),\n",
        "            torch.tensor(self.train_labels, dtype=torch.long)\n",
        "        )\n",
        "        return DataLoader(train_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Create a TensorDataset from features and labels\n",
        "        val_dataset = TensorDataset(\n",
        "            torch.tensor(self.val_features, dtype=torch.float32),\n",
        "            torch.tensor(self.val_labels, dtype=torch.long)\n",
        "        )\n",
        "        return DataLoader(val_dataset, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Create a TensorDataset from features and labels\n",
        "        test_dataset = TensorDataset(\n",
        "            torch.tensor(self.test_features, dtype=torch.float32),\n",
        "            torch.tensor(self.test_labels, dtype=torch.long)\n",
        "        )\n",
        "        return DataLoader(test_dataset, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)"
      ],
      "metadata": {
        "id": "6JX2DV_-UxnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training module"
      ],
      "metadata": {
        "id": "JBWSuYApFu7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class train_model(pl.LightningModule):\n",
        "    def __init__(self, model=None, losses_dict=None, hparams=hparams):\n",
        "    # def __init__(self, hparams=hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.model = model\n",
        "        self.loss_fn = losses_dict[hparams['criterion']]\n",
        "        self.lr = hparams['lr']\n",
        "        self.wd = hparams['weight_decay']\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        h = self(x)\n",
        "        loss = self.loss_fn(h, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        h = self(x)\n",
        "        loss = self.loss_fn(h, y)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        h = self(x)\n",
        "        loss = self.loss_fn(h, y)\n",
        "        preds = torch.argmax(h, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)\n",
        "        return {'loss': loss, 'preds': preds, 'y': y}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr,\n",
        "                                weight_decay=self.wd)"
      ],
      "metadata": {
        "id": "kQYHpiYnFNWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "I0QXX3afFxzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ModelCheckpoint callbacks to save the best validation models\n",
        "#Approach #1\n",
        "checkpoint_callback_img = ModelCheckpoint(\n",
        "    monitor='val_loss',       # Monitor validation loss\n",
        "    dirpath=CHECKPOINT_PATH,  # Directory to save checkpoints\n",
        "    filename=f'best_model_{ARCHITECTURE}_{SEED}_img',# Checkpoint filename\n",
        "    save_top_k=1,             # Save only the best model\n",
        "    mode='min',               # Minimize validation loss\n",
        ")\n",
        "#Approach #2\n",
        "checkpoint_callback_tab = ModelCheckpoint(\n",
        "    monitor='val_loss',       # Monitor validation loss\n",
        "    dirpath=CHECKPOINT_PATH,  # Directory to save checkpoints\n",
        "    filename=f'best_model_{ARCHITECTURE}_{SEED}_tab',# Checkpoint filename\n",
        "    save_top_k=1,             # Save only the best model\n",
        "    mode='min',               # Minimize validation loss\n",
        ")"
      ],
      "metadata": {
        "id": "E3LQ7ME162cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "SpGtoJicGCJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "W2bTStw6J_NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=None, params=hparams):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, params['n_classes'])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(params['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input if it's an image (shape: [batch_size, 1, im_size, im_size])\n",
        "        if x.dim() == 4:  # Check if input is an image\n",
        "            x = x.view(x.size(0), -1)  # Flatten to [batch_size, im_size * im_size]\n",
        "        elif x.dim() == 2:  # Check if input is tabular data (shape: [batch_size, n_feat])\n",
        "            pass  # No need to flatten\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected input shape: {x.shape}. Expected [batch_size, 1, im_size, im_size] or [batch_size, n_feat].\")\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4vmhXlcyGDRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss functions"
      ],
      "metadata": {
        "id": "rHm8wnbnGEnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a loss function class, or use a standart one."
      ],
      "metadata": {
        "id": "8z05aQ7cQTm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss maden from scratch (just in case)\n",
        "class CEplus(nn.Module):\n",
        "    def __init__(self, reduction='mean'):\n",
        "        super(CEplus, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Compute softmax probabilities\n",
        "        prob = nn.functional.softmax(x, 1)\n",
        "        # Compute log probabilities\n",
        "        log_prob = -1.0 * torch.log(prob)\n",
        "        # Gather the log probabilities for the true labels\n",
        "        loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss.squeeze()  # Remove extra dimension for consistency\n",
        "        else:\n",
        "            raise ValueError(\"Invalid reduction option.\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "losses_dict = {'CE': nn.CrossEntropyLoss(),\n",
        "               'CEplus': CEplus(),\n",
        "}\n",
        "losses_dict_red = {'CE': nn.CrossEntropyLoss(reduction='none'),\n",
        "                   'CEplus': CEplus(reduction='none'),\n",
        "}"
      ],
      "metadata": {
        "id": "8auVRUCKGEG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "CWrc-f3sWDDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(dataloader,model,loss_fn_red):\n",
        "    # Collect images, predictions, and losses\n",
        "    images = []\n",
        "    preds  = []\n",
        "    labels = []\n",
        "    losses = []\n",
        "    correct= 0\n",
        "    total  = 0\n",
        "    for batch in dataloader:\n",
        "        x, y = batch\n",
        "        with torch.no_grad():\n",
        "            h = model(x)\n",
        "            loss = loss_fn_red(h,y)\n",
        "            pred = torch.argmax(h, dim=1)\n",
        "        correct += (pred == y).sum().item()  # Number of correct predictions\n",
        "        total += y.size(0)  # Total number of samples\n",
        "\n",
        "        images.extend(x.cpu())\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        labels.extend(y.cpu().numpy())\n",
        "        losses.extend(loss.cpu().numpy())\n",
        "    acc = correct / total\n",
        "    return images, preds, labels, losses, acc"
      ],
      "metadata": {
        "id": "7793mMFKWFYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature extractor\n",
        "\n",
        "Extracts geometric features of images"
      ],
      "metadata": {
        "id": "dAynx5tFiIjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(image):\n",
        "    \"\"\"\n",
        "    Extract geometric and statistical features from a single MNIST image.\n",
        "    :param image: A 28x28 numpy array (MNIST image).\n",
        "    :return: A list of features.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Normalize the image to [0, 255] for better thresholding\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    # 1. Mean Pixel Intensity\n",
        "    mean_intensity = np.mean(image)\n",
        "    features.append(mean_intensity)\n",
        "\n",
        "    # 2. Standard Deviation of Pixel Intensity\n",
        "    std_intensity = np.std(image)\n",
        "    features.append(std_intensity)\n",
        "\n",
        "    # 3. Number of Edges (using Sobel filter)\n",
        "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    edges = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "    num_edges = np.sum(edges > 50)  # Threshold to count edges\n",
        "    features.append(num_edges)\n",
        "\n",
        "    # 4. Aspect Ratio\n",
        "    _, binary_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) > 0:\n",
        "        x, y, w, h = cv2.boundingRect(contours[0])\n",
        "        aspect_ratio = float(w) / h if h != 0 else 0\n",
        "    else:\n",
        "        aspect_ratio = 0\n",
        "    features.append(aspect_ratio)\n",
        "\n",
        "    # 5. Center of Mass\n",
        "    moments = cv2.moments(image)\n",
        "    if moments[\"m00\"] != 0:\n",
        "        cx = moments[\"m10\"] / moments[\"m00\"]\n",
        "        cy = moments[\"m01\"] / moments[\"m00\"]\n",
        "    else:\n",
        "        cx, cy = 0, 0\n",
        "    features.append(cx)\n",
        "    features.append(cy)\n",
        "\n",
        "    # 6. Number of Contours\n",
        "    num_contours = len(contours)\n",
        "    features.append(num_contours)\n",
        "\n",
        "    # 7. Area of the Digit\n",
        "    if len(contours) > 0:\n",
        "        area = cv2.contourArea(contours[0])\n",
        "    else:\n",
        "        area = 0\n",
        "    features.append(area)\n",
        "\n",
        "    # 8. Perimeter Length\n",
        "    if len(contours) > 0:\n",
        "        perimeter = cv2.arcLength(contours[0], closed=True)\n",
        "    else:\n",
        "        perimeter = 0\n",
        "    features.append(perimeter)\n",
        "\n",
        "    # 9. Inertia (Second Moment of Area)\n",
        "    if len(contours) > 0:\n",
        "        inertia = moments[\"mu20\"] + moments[\"mu02\"]\n",
        "    else:\n",
        "        inertia = 0\n",
        "    features.append(inertia)\n",
        "\n",
        "    # 10. Compactness (Perimeter^2 / Area)\n",
        "    if area > 0:\n",
        "        compactness = (perimeter ** 2) / area\n",
        "    else:\n",
        "        compactness = 0\n",
        "    features.append(compactness)\n",
        "\n",
        "    # 11. Eccentricity\n",
        "    if len(contours) > 0 and len(contours[0]) >= 5:  # Check if contour has at least 5 points\n",
        "        (_, _), (major_axis, minor_axis), _ = cv2.fitEllipse(contours[0])\n",
        "\n",
        "        # Ensure minor_axis <= major_axis\n",
        "        if minor_axis > major_axis:\n",
        "            major_axis, minor_axis = minor_axis, major_axis\n",
        "\n",
        "        # Clip the argument of np.sqrt to ensure it is non-negative\n",
        "        ratio = (minor_axis ** 2) / (major_axis ** 2)\n",
        "        ratio = np.clip(ratio, 0, 1)  # Clip to [0, 1]\n",
        "\n",
        "        eccentricity = np.sqrt(1 - ratio)\n",
        "    else:\n",
        "        eccentricity = 0\n",
        "    features.append(eccentricity)\n",
        "\n",
        "    # Enter your code here to add one or more additional features (bonus track)\n",
        "\n",
        "    return features\n",
        "\n",
        "def create_tabular_dataset(dataset):\n",
        "    \"\"\"\n",
        "    Create a tabular dataset from MNIST images by extracting features.\n",
        "    :param dataset: MNIST dataset (e.g., torchvision.datasets.MNIST).\n",
        "    :return: A tuple (X, y) where X is the feature matrix and y is the label vector.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for image, label in dataset:\n",
        "        # Convert image to numpy array\n",
        "        image_np = image.squeeze().numpy()\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_features(image_np)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "WHLCG4HaiaM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "HAPUCxThGgsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot image samples with top loss values\n",
        "def top_losses_vis(vis_params, images, preds, labels, losses):\n",
        "    num_imgs = vis_params['num_samples']\n",
        "    top_loss_indices = np.argsort(losses)[-num_imgs:]\n",
        "\n",
        "    plt.figure(figsize=(num_imgs*2, 2))\n",
        "    for i, idx in enumerate(top_loss_indices):\n",
        "        plt.subplot(1, num_imgs, i + 1)\n",
        "        plt.imshow(images[idx].squeeze(), cmap='gray')\n",
        "        plt.title(f'True: {labels[idx]}\\nPred: {preds[idx]}\\nLoss: {losses[idx]:.2f}')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "def conf_mat(figsize):\n",
        "    plt.figure(figsize)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gznqmB6aQbEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach \\# 1: Feature Extraction and Image Classification Using an ANN"
      ],
      "metadata": {
        "id": "KemJG62D7EJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: historically, approach #1 is more modern than appooach #2 presented in the next chapter of this notebook."
      ],
      "metadata": {
        "id": "a568P0IS-3dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset and Data Loaders"
      ],
      "metadata": {
        "id": "7d0C987gzzlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the dataset, the dataloader, and the training module"
      ],
      "metadata": {
        "id": "tQmBPmYH21V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = MNISTDataModule(hparams)"
      ],
      "metadata": {
        "id": "jrjw6mU-z36-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "oBfy6DZL0tii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the loss function, and it's version with reduction to calculate loss per image"
      ],
      "metadata": {
        "id": "Xyd4kU-bWfri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses_dict[hparams['criterion']]\n",
        "loss_fn_red = losses_dict_red[hparams['criterion']]"
      ],
      "metadata": {
        "id": "4jrsIuouk9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model and the trainer. Log the hyperparameters"
      ],
      "metadata": {
        "id": "EM5bW4Kh2uoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(SEED) #on more time, just in case\n",
        "model = train_model(model=MLP(input_size=hparams['im_size']**2), losses_dict=losses_dict)\n",
        "# Log hyperparameters to ClearML\n",
        "task.connect(model.hparams)\n",
        "\n",
        "trainer = Trainer(max_epochs=hparams['num_epochs'],\n",
        "                  callbacks=[checkpoint_callback_img],\n",
        "                  accelerator=\"auto\", devices=\"auto\")\n"
      ],
      "metadata": {
        "id": "JZcCmZdr096m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "YvXe2Rv02-tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "dRKgQ-Vk2_T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log the best model"
      ],
      "metadata": {
        "id": "T3M0fa6mfGVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = checkpoint_callback_img.best_model_path\n",
        "task.update_output_model(model_path=best_model_path, auto_delete_file=False)"
      ],
      "metadata": {
        "id": "mOwOvxW-fJaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model"
      ],
      "metadata": {
        "id": "pLNIItae4zOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_img.best_model_path"
      ],
      "metadata": {
        "id": "YRn6PFY6nl7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best model checkpoint"
      ],
      "metadata": {
        "id": "_bpGZnhifqjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = train_model.load_from_checkpoint(best_model_path,\n",
        "                                              model=MLP(input_size=hparams['im_size']**2),\n",
        "                                              losses_dict=losses_dict)"
      ],
      "metadata": {
        "id": "xZ9ZTiEmfsol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Metric and the loss values for the test set (for a batch, probably)"
      ],
      "metadata": {
        "id": "AfwaH7rx919S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.test(best_model, datamodule=data_module)\n",
        "print(test_results)"
      ],
      "metadata": {
        "id": "_R-Pzvdi4r9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metrics for the entire test set"
      ],
      "metadata": {
        "id": "tUkYF0OFhgTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_preds, test_labels, test_losses, test_acc =  metrics(data_module.test_dataloader(),\n",
        "                                                             best_model, loss_fn_red)\n",
        "print(f'Accuracy for the entire test set is: {test_acc}')\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)"
      ],
      "metadata": {
        "id": "NH0K1eLBhmKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the test results"
      ],
      "metadata": {
        "id": "tnG40UO19sxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the confusion matrix for the test set"
      ],
      "metadata": {
        "id": "AEsU4snCv3fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat(vis_params['fig_size'])"
      ],
      "metadata": {
        "id": "3EYYJi66vqFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the test samples of top losses"
      ],
      "metadata": {
        "id": "s6OPAzBeGmqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_losses_vis(vis_params, test_images, test_preds, test_labels, test_losses)"
      ],
      "metadata": {
        "id": "dVbrSTvXfsk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear some memory and stop logging the task"
      ],
      "metadata": {
        "id": "uq_wzV6lr468"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del data_module, model, trainer, best_model, test_images, test_preds, test_labels, test_losses\n",
        "task.close()"
      ],
      "metadata": {
        "id": "KR-MfD4ysDyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach \\# 2: Hand-Designed Feature Extraction and the Following Tabular Data Classification using the ANN"
      ],
      "metadata": {
        "id": "IPmXFOmrIcEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Tracking a New Task"
      ],
      "metadata": {
        "id": "XLWw_RJY667b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here to create a new task entiteled f'Lab_1_seed={SEED}_tab'\n",
        "#in the same project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD6G-g1k7E2Y",
        "outputId": "52e11dd8-f367-41e0-c4b5-c04bfb126e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML is configured correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset and Data Loaders"
      ],
      "metadata": {
        "id": "chDQvzpNskcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here to:\n",
        "# Initialize the TabularDataModule\n",
        "# data_module = ...\n",
        "\n",
        "# Prepare and setup the data\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "# Example: Access the training data, check if the feature and labels shapes are correct\n",
        "train_dataloader = data_module.train_dataloader()\n",
        "for batch in train_dataloader:\n",
        "    features, labels = batch\n",
        "    print(\"Features shape:\", features.shape)  # Should be (batch_size, num_features)\n",
        "    print(\"Labels shape:\", labels.shape)      # Should be (batch_size,)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW6h7g2FskcP",
        "outputId": "809adccc-4c84-4749-a7e9-c4943a07a161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: torch.Size([64, 12])\n",
            "Labels shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "GpvjdUb8skcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the dataset, the dataloader, and the training module"
      ],
      "metadata": {
        "id": "MBEvwfeaskcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(SEED) #just in case\n",
        "#Enter your code here to create the model\n",
        "#model = ...\n",
        "# Log hyperparameters to ClearML\n",
        "task.connect(model.hparams)\n",
        "# Start the trainer with appropriate callbacks\n",
        "# trainer = Trainer(max_epochs=...,\n",
        "                  # callbacks=...,\n",
        "                  # accelerator=\"auto\", devices=\"auto\")\n"
      ],
      "metadata": {
        "id": "cSAs_aSSskcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if the model looks fine\n",
        "model"
      ],
      "metadata": {
        "id": "1lQDN0jGRjuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "Fw6apZm7skcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "yC2IzDjFskcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log the best model"
      ],
      "metadata": {
        "id": "n1vb6XRIxO0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here to define the best model path\n",
        "# best_model_path =\n",
        "task.update_output_model(model_path=best_model_path, auto_delete_file=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d626c84e-2321-47df-cdb7-063feeba7fa4",
        "id": "ZiDDFBAwxO0q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://files.clear.ml/CV-2025/Lab_1_seed=42_tab.d5cf2102adb84369901c4eeb58c7fee1/models/best_model_MLP_42_tab.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Model"
      ],
      "metadata": {
        "id": "yDNUIQa8LV2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback_tab.best_model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5dda6de-0139-4d0d-a104-33db64183f13",
        "id": "3jRFxaxTLV2i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/saved_models/best_model_MLP_42_tab.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n5Ho3cN_w5Vh",
        "outputId": "64fce10c-0ad4-456b-8eb4-98ea6c109ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/saved_models/best_model_MLP_42_tab.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best model checkpoint"
      ],
      "metadata": {
        "id": "RzviGRBFLV2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here to load the best model from the checkpoint usine features.shape[-1] as the input size\n",
        "# best_model ="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a941ae69-348e-45c1-c5d7-a521a65d8d7f",
        "id": "bhhx5OhwLV2j"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:209: UserWarning:\n",
            "\n",
            "Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Metric and the loss values for the test set (for a batch, probably)"
      ],
      "metadata": {
        "id": "BAvy5uXXLV2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.test(best_model, datamodule=data_module)\n",
        "print(test_results)"
      ],
      "metadata": {
        "id": "s9jqzOPuLV2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metrics for the entire test set"
      ],
      "metadata": {
        "id": "nlyNVAe26ZC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "*_, test_acc =  metrics(data_module.test_dataloader(),\n",
        "                       best_model, loss_fn_red)\n",
        "print(f'Accuracy for the entire test set is: {test_acc}')\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18e69ed-68de-4cc8-bffc-0573183118b5",
        "id": "15WmA0iA6ZC8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for the entire test set is: 0.3404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the test results"
      ],
      "metadata": {
        "id": "_SBZKWvxLV2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the confusion matrix for the test set"
      ],
      "metadata": {
        "id": "XFRRFWcOLV2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here to visualize the confusion matrix"
      ],
      "metadata": {
        "id": "pOARMvyYLV2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Logging"
      ],
      "metadata": {
        "id": "mNdh0lFx9kZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task.close()"
      ],
      "metadata": {
        "id": "2Vhd6JP74r3h",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results and Discussion"
      ],
      "metadata": {
        "id": "WrA52u-qfM5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All experiments were performed five times with random seeds of [42, 0, 17, 9, 3] (see the table below). The final metrics were calculated as means and standard deviations over five runs. The minimum values of the loss function on validation determined the best checkpoints of the models (see Figure 1).  "
      ],
      "metadata": {
        "id": "QFVsSYjshtYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!!! Please implement the experiments, fill the table and plot the figure below. !!!"
      ],
      "metadata": {
        "id": "WZ5Sg5K8fVxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Table 1.** Results of a series of simulation experiments on the MNIST dataset comparing two approaches: automatic feature extraction using an artificial neural network (ANN), and a hand-designed feature extractor combined with an ANN classifier.\n",
        "\n",
        "| # | Approach     | Arch.| #train.param. | Seed | Accuracy, \\%|\n",
        "|---|--------------|------|---------------|------|-------------|\n",
        "| 1 | Img. classif.| MLP  | 109E+3        | 42   | 00.0        |\n",
        "|   |              |      |               | 0    | 00.0        |\n",
        "|   |              |      |               | 17   | 00.0        |\n",
        "|   |              |      |               | 9    | 00.0        |\n",
        "|   |              |      |               | 3    | 00.0        |\n",
        "|---|--------------|------|---------------|------|-------------|\n",
        "| 2 | Tab. classif.| MLP  | 000,000       | 42   | 00.0        |\n",
        "|   |              |      |               | 0    | 00.0        |\n",
        "|   |              |      |               | 17   | 00.0        |\n",
        "|   |              |      |               | 9    | 00.0        |\n",
        "|   |              |      |               | 3    | 00.0        |"
      ],
      "metadata": {
        "id": "k6k6xpfcbNRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter your code here to plot the figure using Json data from ClearML"
      ],
      "metadata": {
        "id": "xXwlXULSlaOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Figure 1.** Comparison of the validation plots for runs with different model initializations (using different seeds)."
      ],
      "metadata": {
        "id": "D3gBXM3vlZNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing the result, the first (image processing) and the second (hand-designed features processing) approaches demonstrated accuracy of $ 00.0 \\pm 0.0$, and $ 00.0 \\pm 0.0$, respectively."
      ],
      "metadata": {
        "id": "XRUNVqPLfwyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "ImzQ9H4uAS85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter you text here.\n",
        "\n",
        "Please note that the conclusion is not only a declaration of the obtained results. It should also answer relevant questions related to the work, providing insights that enhance the reader's understanding, make their life a bit easier, and contribute to making the world a bit better — or at least a bit clearer.\n"
      ],
      "metadata": {
        "id": "xES-SUhyAStV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "xJNDWjwf6iBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. How would you use ClearML to track experiments and compare the performance of different models?\n",
        "2. What is the role of the random seed in training, and how does it affect reproducibility?\n",
        "3. What is the purpose of the `prepare_data` method in the `MNISTDataModule`?\n",
        "4. Why is the dataset split into training, validation, and test sets? What is the role of each set?\n",
        "5. What does the `transforms.Normalize` function do, and why is it important for training neural networks?\n",
        "6. Explain the architecture of the MLP model used in this lab. What are the dimensions of the input layer, hidden layers, and output layer? Why is the input size `28 * 28` for the MNIST dataset?\n",
        "7. What loss function is used in this lab, and why is it suitable for this task? Which optimizer is used, and what is its learning rate?\n",
        "8. What transformations are applied to the MNIST dataset before training? Why is normalization important, and what values are used for normalization in this lab?\n",
        "9. What are the geometric features extracted from the MNIST images in the `extract_features` function? Explain each feature briefly.\n",
        "10. What is the purpose of the `TabularDataModule`? How does it differ from the `MNISTDataModule`?\n",
        "11. How does the `TabularDataModule` handle the conversion of image data into tabular data?\n",
        "12. What is the role of the `TensorDataset` class in the `TabularDataModule`?\n",
        "13. How does the `configure_optimizers` method work, and why is it necessary?\n",
        "14. What is the significance of the `trainer.fit` and `trainer.test` methods in PyTorch Lightning?\n",
        "15. What is the purpose of the `self.log` method in PyTorch Lightning? Where can you view the logged metrics?\n",
        "16. Are the models prone to overfitting? Was this possibility considered and addressed during the modeling process?\n",
        "17. How is accuracy calculated during the testing phase? What does the confusion matrix represent, and how can it help in evaluating the model's performance?\n",
        "18. What does the \"Top Losses\" visualization represent? How can it help in debugging or improving the model?\n",
        "\n",
        "## Bonus Questions (Optional)\n",
        "1. What is the purpose of using ClearML in this lab? How does it help in managing machine learning experiments, in general?\n",
        "2. What are the advantages and disadvantages of using handcrafted features (e.g., geometric features) versus raw pixel values for image classification?\n",
        "3. How would you adapt the `TabularDataModule` and `TabularModel` for a different dataset (e.g., CIFAR-10)?\n",
        "4. How would you modify the `TabularDataModule` to include additional features (e.g., histogram of pixel intensities)?\n",
        "5. What are the challenges of using handcrafted features for more complex datasets (e.g., high-resolution images)?\n",
        "6. How would you modify the `MLP` architecture to improve its performance on the tabular dataset?\n",
        "7. What other machine learning models (e.g., decision trees, random forests) could be used for the tabular dataset, and how would you implement them?\n",
        "8. How would you perform hyperparameter tuning (e.g., learning rate, batch size) for the `TabularModel`?\n",
        "9. What additional metrics (e.g., precision, recall, F1-score) could you log to evaluate the model’s performance?\n",
        "\n"
      ],
      "metadata": {
        "id": "r15niPd66iuy"
      }
    }
  ]
}